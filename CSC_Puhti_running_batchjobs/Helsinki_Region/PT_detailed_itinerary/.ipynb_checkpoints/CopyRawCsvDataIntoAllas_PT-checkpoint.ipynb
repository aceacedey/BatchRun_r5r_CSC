{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5efd71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os, shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all file paths\n",
    "#data_dir = '/scratch/project_2010418/r5r_detailed_iti_Helsinki_csvfiles/Helsinki_GTFS_April_2023_Transit/Batch_output_0_300'#'/scratch/project_2008743/data-temp'\n",
    "#data_dir = '/scratch/project_2010418/r5r_detailed_iti_Helsinki_csvfiles/Helsinki_GTFS_April_2023_Transit/Batch_output_301_600'\n",
    "#data_dir = '/scratch/project_2010418/r5r_detailed_iti_Helsinki_csvfiles/Helsinki_GTFS_April_2023_Transit/Batch_output_601_900'\n",
    "data_dir = '/scratch/project_2011005/Helsinki_Region_Emission_Calculation/Codes_Car_PT_CO2_calculation_Sept2024/PT_detailed_itinerary/Batch_output'\n",
    "\n",
    "files = glob.glob(os.path.join(data_dir, '*/*.csv'))\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a95555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection s3\n",
    "s3_client = boto3.client(\"s3\", endpoint_url='https://a3s.fi')\n",
    "s3_resource = boto3.resource('s3', endpoint_url='https://a3s.fi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e76d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket(name='Helsinki_GTFS_April_2023_rawcsv')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------- Save to a new Bucket -----------------\n",
    "# define bucket name and object name\n",
    "bucket_name = \"Helsinki_GTFS_April_2023_rawcsv\"\n",
    "# create a new bucket\n",
    "s3_resource.create_bucket(Bucket=bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cec65e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helsinki_H3_r5rDI_2024-09-13_B_0.csv\n",
      "Helsinki_H3_r5rDI_2024-09-13_B_1.csv\n",
      "Helsinki_H3_r5rDI_2024-09-13_B_10.csv\n",
      "Helsinki_H3_r5rDI_2024-09-13_B_100.csv\n",
      "Helsinki_H3_r5rDI_2024-09-13_B_101.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m object_name \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m::])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(object_name)\n\u001b[0;32m----> 8\u001b[0m \u001b[43ms3_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m counter\u001b[38;5;241m=\u001b[39mcounter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# new bucket in the same project\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#s3_resource.Object('Helsinki_GTFS_April_2023_Transit', object_name).upload_file(destination_path)\u001b[39;00m\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/boto3/s3/inject.py:320\u001b[0m, in \u001b[0;36mobject_upload_file\u001b[0;34m(self, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobject_upload_file\u001b[39m(\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m, Filename, ExtraArgs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m ):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Usage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m        transfer.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/boto3/s3/inject.py:145\u001b[0m, in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/boto3/s3/transfer.py:372\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    368\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mupload(\n\u001b[1;32m    369\u001b[0m     filename, bucket, key, extra_args, subscribers\n\u001b[1;32m    370\u001b[0m )\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/site-packages/s3transfer/futures.py:261\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mfailure.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/PUHTI_TYKKY_lJ7Gcw6/miniconda/envs/env1/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for f in sorted(files):\n",
    "    \n",
    "    # Allas name\n",
    "    object_name = (\"/\").join(f.split('/')[-1::])\n",
    "\n",
    "    print(object_name)\n",
    "    s3_resource.Object(bucket_name, object_name).upload_file(f)\n",
    "    counter=counter+1\n",
    "    # new bucket in the same project\n",
    "    #s3_resource.Object('Helsinki_GTFS_April_2023_Transit', object_name).upload_file(destination_path)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79486b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/project_2011005/Helsinki_Region_Emission_Calculation/Codes_Car_PT_CO2_calculation_Sept2024/PT_detailed_itinerary/PT_process_Co2data_into_Allas_using_BatchPY/Helsinki_GTFS_April_2023/Helsinki_H3_r5rDI_2024-09-13_B_101_wCO2.parquet'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_bucket = s3_resource.Bucket(bucket_name)\n",
    "#for my_bucket_object in my_bucket.objects.all():\n",
    "#    print(my_bucket_object.key)\n",
    "f\n",
    "\"_\".join(f[0:-4].split(\"_\")[:3]+f[0:-4].split(\"_\")[4:])\n",
    "object_name = (\"/\").join(f.split('/')[-1::])\n",
    "\"_\".join(object_name[0:-4].split(\"_\")[:3]+object_name[0:-4].split(\"_\")[4:])\n",
    "object_name[0:-4] + \"_wCO2.parquet\"\n",
    "out_dir = '/scratch/project_2011005/Helsinki_Region_Emission_Calculation/Codes_Car_PT_CO2_calculation_Sept2024/PT_detailed_itinerary/PT_process_Co2data_into_Allas_using_BatchPY/Helsinki_GTFS_April_2023/'\n",
    "out_dir + object_name[0:-4] + \"_wCO2.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "881a4142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>from_lat</th>\n",
       "      <th>from_lon</th>\n",
       "      <th>to_id</th>\n",
       "      <th>to_lat</th>\n",
       "      <th>to_lon</th>\n",
       "      <th>option</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>segment</th>\n",
       "      <th>mode</th>\n",
       "      <th>segment_duration</th>\n",
       "      <th>wait</th>\n",
       "      <th>distance</th>\n",
       "      <th>route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89089961b17ffff</td>\n",
       "      <td>60.299523</td>\n",
       "      <td>24.707169</td>\n",
       "      <td>891126d2167ffff</td>\n",
       "      <td>60.238288</td>\n",
       "      <td>24.915463</td>\n",
       "      <td>1</td>\n",
       "      <td>07:40:34</td>\n",
       "      <td>67.9</td>\n",
       "      <td>19731</td>\n",
       "      <td>1</td>\n",
       "      <td>WALK</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89089961b17ffff</td>\n",
       "      <td>60.299523</td>\n",
       "      <td>24.707169</td>\n",
       "      <td>891126d2167ffff</td>\n",
       "      <td>60.238288</td>\n",
       "      <td>24.915463</td>\n",
       "      <td>1</td>\n",
       "      <td>07:40:34</td>\n",
       "      <td>67.9</td>\n",
       "      <td>19731</td>\n",
       "      <td>2</td>\n",
       "      <td>BUS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2570</td>\n",
       "      <td>2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89089961b17ffff</td>\n",
       "      <td>60.299523</td>\n",
       "      <td>24.707169</td>\n",
       "      <td>891126d2167ffff</td>\n",
       "      <td>60.238288</td>\n",
       "      <td>24.915463</td>\n",
       "      <td>1</td>\n",
       "      <td>07:40:34</td>\n",
       "      <td>67.9</td>\n",
       "      <td>19731</td>\n",
       "      <td>3</td>\n",
       "      <td>WALK</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89089961b17ffff</td>\n",
       "      <td>60.299523</td>\n",
       "      <td>24.707169</td>\n",
       "      <td>891126d2167ffff</td>\n",
       "      <td>60.238288</td>\n",
       "      <td>24.915463</td>\n",
       "      <td>1</td>\n",
       "      <td>07:40:34</td>\n",
       "      <td>67.9</td>\n",
       "      <td>19731</td>\n",
       "      <td>4</td>\n",
       "      <td>BUS</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12923</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89089961b17ffff</td>\n",
       "      <td>60.299523</td>\n",
       "      <td>24.707169</td>\n",
       "      <td>891126d2167ffff</td>\n",
       "      <td>60.238288</td>\n",
       "      <td>24.915463</td>\n",
       "      <td>1</td>\n",
       "      <td>07:40:34</td>\n",
       "      <td>67.9</td>\n",
       "      <td>19731</td>\n",
       "      <td>5</td>\n",
       "      <td>WALK</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           from_id   from_lat   from_lon            to_id     to_lat  \\\n",
       "0  89089961b17ffff  60.299523  24.707169  891126d2167ffff  60.238288   \n",
       "1  89089961b17ffff  60.299523  24.707169  891126d2167ffff  60.238288   \n",
       "2  89089961b17ffff  60.299523  24.707169  891126d2167ffff  60.238288   \n",
       "3  89089961b17ffff  60.299523  24.707169  891126d2167ffff  60.238288   \n",
       "4  89089961b17ffff  60.299523  24.707169  891126d2167ffff  60.238288   \n",
       "\n",
       "      to_lon  option departure_time  total_duration  total_distance  segment  \\\n",
       "0  24.915463       1       07:40:34            67.9           19731        1   \n",
       "1  24.915463       1       07:40:34            67.9           19731        2   \n",
       "2  24.915463       1       07:40:34            67.9           19731        3   \n",
       "3  24.915463       1       07:40:34            67.9           19731        4   \n",
       "4  24.915463       1       07:40:34            67.9           19731        5   \n",
       "\n",
       "   mode  segment_duration  wait  distance route  \n",
       "0  WALK              12.2   0.0       855   NaN  \n",
       "1   BUS               5.0   2.2      2570  2349  \n",
       "2  WALK               0.3   0.0        15   NaN  \n",
       "3   BUS              23.0   7.5     12923  2345  \n",
       "4  WALK               5.3   0.0       339   NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04edf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "\n",
    "\n",
    "Car_share_Hsl = 0.35 ## Car\n",
    "PT_share_Hsl = 0.23 ## Public transport\n",
    "Bike_share_Hsl = 0.08  ## Bicycle\n",
    "Walk_share_Hsl = 0.33  ## Walking\n",
    "Other_share_Hsl = 0.01 ## Other\n",
    "\n",
    "ghg_factors = pd.read_csv(\"Data_CO2/LCA_gCO2_per_pkm_by_transport_mode.csv\",index_col=0)\n",
    "ghg_factors.loc['Total_gCO2'] = ghg_factors.sum(axis=0)\n",
    "ghg_factors.head()\n",
    "\n",
    "# Create a function that returns travel mode specific co2 emission factors\n",
    "def CO2_emission_factors(mode, ghg_factors):\n",
    "    \"\"\"\n",
    "    Convenience function that returns mode specific GHG emission factors (average)\n",
    "    based on International Transport Forum's LCA Emission estimates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    mode : str\n",
    "       Name of the travel mode.\n",
    "\n",
    "    ghg_factors : pd.DataFrame\n",
    "       A DataFrame containing information about the emissions of different types of vehicles.\n",
    "      \n",
    "    \"\"\"\n",
    "    # Here, we don't assume walking produces emissions (although it does..due to eating)\n",
    "    if mode == \"WALK\":\n",
    "        co2_value = 0\n",
    "    elif mode in [\"TRAM\", \"SUBWAY\", \"RAIL\"]:\n",
    "        co2_value =  ghg_factors.loc['Total_gCO2',['Metro/urban train']].mean()\n",
    "    elif mode == \"BUS\":\n",
    "        co2_value =  ghg_factors.loc['Total_gCO2',['Bus - ICE', 'Bus - HEV', 'Bus - BEV','Bus - BEV (two packs)', 'Bus - FCEV']].mean()\n",
    "    elif mode == \"FERRY\":\n",
    "        co2_value = 36 ## to be change here\n",
    "    else:\n",
    "        print(str(mode))\n",
    "        raise ValueError(\"Unknown Transit mode found!\")\n",
    "    return co2_value\n",
    "\n",
    "import os, shutil\n",
    "import glob    \n",
    "data_dir = '/scratch/project_2011005/Helsinki_Region_Emission_Calculation/Codes_Car_PT_CO2_calculation_Sept2024/PT_detailed_itinerary/Batch_output'\n",
    "\n",
    "out_dir = '/scratch/project_2011005/Helsinki_Region_Emission_Calculation/Codes_Car_PT_CO2_calculation_Sept2024/PT_detailed_itinerary/PT_process_Co2data_into_Allas_using_BatchPY/Helsinki_GTFS_April_2023/'\n",
    "\n",
    "files = glob.glob(os.path.join(data_dir, '*/*.csv'))    \n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "# create connection s3\n",
    "s3_client = boto3.client(\"s3\", endpoint_url='https://a3s.fi')\n",
    "# create connection s3\n",
    "s3_resource = boto3.resource('s3', endpoint_url='https://a3s.fi')\n",
    "\n",
    "# define bucket name and object name\n",
    "raw_bucket_name = \"Helsinki_GTFS_April_2023_rawcsv\"\n",
    "# create a new bucket\n",
    "s3_resource.create_bucket(Bucket=raw_bucket_name)\n",
    "\n",
    "\n",
    "##read local files one by one, upload to allas, process and save to local disk again , then upload to allas again \n",
    "for f in sorted(files):\n",
    "    # Allas name\n",
    "    object_name = (\"/\").join(f.split('/')[-1::])\n",
    "    print(object_name)\n",
    "    s3_resource.Object(bucket_name, object_name).upload_file(f)\n",
    "\n",
    "#my_bucket = s3_resource.Bucket(raw_bucket_name)\n",
    "#for my_bucket_object in my_bucket.objects.all():\n",
    "##    temp_object_name = my_bucket_object.key\n",
    "##    f = temp_object_name.split(\"/\")[-1]\n",
    "##    response = s3_client.get_object(Bucket=raw_bucket_name, Key=temp_object_name)\n",
    "##    temp_travel_details= pd.read_csv(response.get(\"Body\"), sep=\",\")\n",
    "    temp_travel_details= pd.read_csv(f)\n",
    "    temp_travel_details['ghg_emission_factor'] = temp_travel_details.apply(lambda x: CO2_emission_factors(x['mode'], ghg_factors), axis=1)\n",
    "    temp_travel_details[\"GHG_emissions_in_grams\"] = temp_travel_details[\"distance\"]/1000 * temp_travel_details[\"ghg_emission_factor\"]\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"pt_departure_time\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"])[\"departure_time\"].unique().apply(lambda x:x[0])\n",
    "    temp_df[\"pt_dist\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"])[\"total_distance\"].unique().apply(lambda x:x[0])\n",
    "    temp_df[\"pt_time\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"])[\"total_duration\"].unique().apply(lambda x:x[0])\n",
    "    temp_df[\"pt_co2\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"]).GHG_emissions_in_grams.sum()\n",
    "    temp_df[\"pt_trip_seq\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"]).agg({\"mode\":pd.Series.to_list})\n",
    "    temp_df[\"pt_time_seq\"]= temp_travel_details.groupby([\"from_id\", \"to_id\"]).agg({\"segment_duration\":pd.Series.to_list})  #,])#.to_list()\n",
    "    temp_df[\"pt_dist_seq\"]= temp_travel_details.groupby([\"from_id\", \"to_id\"]).agg({\"distance\":pd.Series.to_list}) \n",
    "    temp_df[\"pt_unique_modes\"] = temp_travel_details.groupby([\"from_id\", \"to_id\"])[\"mode\"].nunique()\n",
    "    temp_df.reset_index(inplace=True)\n",
    "    temp_df[\"geometry\"] =temp_df.to_id.apply(lambda x: shapely.geometry.Polygon(h3.h3_to_geo_boundary(x, geo_json=False)))\n",
    "    \n",
    "##    del_date_str = \"_\".join(f[0:-4].split(\"_\")[:3]+f[0:-4].split(\"_\")[4:])\n",
    "    ### put container name and \n",
    "##    new_fname =  \"Helsinki_GTFS_April_2023/Batch_output_Transit_r5r_wco2_parquet/\"+ del_date_str + \"_wCO2.parquet\" \n",
    "    new_fname =  out_dir + object_name[0:-4] + \"_wCO2.parquet\"\n",
    "    gpd.GeoDataFrame(temp_df.round(2),crs=\"EPSG:4326\").to_parquet(new_fname,compression=None)\n",
    "    #s3_resource.Object(output_bucket_name, new_fname).upload_file(temp_df.round(2))\n",
    "    #print(f)\n",
    "    \n",
    "### Upload to allas\n",
    "output_bucket_name = \"Helsinki_GTFS_April_2023_wCO2\"#\"Helsinki_PT_detailed_itinerary_r5r_wCO2\"\n",
    "# create connection s3\n",
    "s3_resource = boto3.resource('s3', endpoint_url='https://a3s.fi')\n",
    "# list uploaded files in Bucket\n",
    "\n",
    "#data_bucket_name = \"Helsinki_PT_detailed_itinerary_r5r_wCO2data\"\n",
    "# create a new bucket\n",
    "s3_resource.create_bucket(Bucket=output_bucket_name)\n",
    "#s3_resource.Object(output_bucket_name, object_name).upload_file(source_path)\n",
    "import os, glob\n",
    "data_dir = out_dir  # 'Helsinki_GTFS_April_2023/Batch_output_Transit_r5r_wco2_parquet/'\n",
    "my_out_bucket = s3_resource.Bucket(output_bucket_name)\n",
    "\n",
    "files = glob.glob(os.path.join(data_dir, '*.parquet'))\n",
    "for source_file_path in sorted(files):\n",
    "    \n",
    "    # Allas name\n",
    "    object_name = (\"/\").join(source_file_path.split('/')[-3::])\n",
    "\n",
    "    print(object_name)\n",
    "    s3_resource.Object(output_bucket_name, object_name).upload_file(source_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
